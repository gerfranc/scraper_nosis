# -*- coding: utf-8 -*-
"""Scrap_NOSIS_vf18_05_2023

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YaWHo3pSIK6V7lai7p4Mi-DJZV-qeMf_
"""

!pip install pdfplumber pandas tqdm

"""
Script optimizado para extraer informaci√≥n estructurada de PDFs y convertirla en DataFrames.
Versi√≥n mejorada con correcciones para manejar posiciones X y extracci√≥n de datos.
"""

# 1. IMPORTACIONES - Organizadas por tipo
import re
import os
import logging
import warnings
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Tuple, Optional

# Configuraci√≥n para suprimir los warnings de pdfminer
logging.getLogger('pdfminer').setLevel(logging.ERROR)

# Bibliotecas de terceros
import pdfplumber
import pandas as pd
from tqdm.notebook import tqdm  # Para mostrar barras de progreso

# Si est√°s usando Google Colab
try:
    from google.colab import files
    from google.colab import drive  # Para acceder a Google Drive
    IN_COLAB = True
except ImportError:
    IN_COLAB = False

# 2. CONFIGURACI√ìN - Datos externalizados para facilitar mantenimiento
# Constantes y configuraciones
CONFIG = {
    'roles': [
        "Director", "Director Suplente", "Empleador", "Empleado", "C√≥nyuge",
        "Vicepresidente", "ex", "ex Director", "Presidente", "Firmante cheques",
        "Firmante", "Suplente", "Principal", "Consultado", "Socio"
    ],
    'tipos_empresa': ["SA", "S.A.", "SRL", "S.R.L.", "S.A", "SRL"],
    'prefijos_validos': ["Ex", "ex"],
    'patrones': {
        'cuit': r'^(\d{2}-\d{8,}-\d)',
        'edad': r'\b(\d{1,3}\s+a√±os|fallecido)\b',
        'fecha': r'(\d{2}/\d{2}/\d{4})',
        'arbol_grafo': [r'√ÅRBOL(.*?)GRAFO', r'ARBOL(.*?)GRAFO'],
        'espacios': r'\s{2,}',
        'primer_digito': r'(\d)'  # Patr√≥n para encontrar el primer d√≠gito
    },
    'columnas_df': ['CUIT', 'Nombre', 'Rol', 'Edad', 'Fecha', 'Consultado', 'Jerarquia', 'PosicionX', 'Archivo']
}

# 3. DEFINICI√ìN DE FUNCIONES

def extraer_texto_pdf(ruta_pdf: str) -> tuple:
    """
    Extrae el texto de un archivo PDF junto con las coordenadas exactas de cada car√°cter.
    Retorna una tupla con el texto completo y un diccionario de caracteres con coordenadas.
    """
    texto_completo = []
    caracteres_por_linea = {}
    todas_coordenadas = []
    lineas_ordenadas = []  # Lista para mantener las l√≠neas en orden
    arbol_iniciado = False  # Variable para controlar si estamos en la secci√≥n √ÅRBOL
    arbol_lineas = []       # Lista para almacenar l√≠neas de la secci√≥n √ÅRBOL

    try:
        # Suprimimos los warnings espec√≠ficamente durante la extracci√≥n
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=UserWarning)

            with pdfplumber.open(ruta_pdf) as pdf:
                print(f"  üìÑ Informaci√≥n del PDF: {os.path.basename(ruta_pdf)}")
                print(f"  - N√∫mero de p√°ginas: {len(pdf.pages)}")

                # Mostramos informaci√≥n de la primera p√°gina para diagn√≥stico
                if len(pdf.pages) > 0:
                    page = pdf.pages[0]
                    print(f"  - MediaBox: {page.mediabox}")
                    print(f"  - CropBox: {page.cropbox or 'No definido (usando MediaBox)'}")

                # Procesamos cada p√°gina
                for page_num, pagina in enumerate(pdf.pages):
                    # Extraemos el texto normal para mantener la compatibilidad
                    texto = pagina.extract_text()
                    if texto:
                        texto_completo.append(texto)

                    # Extraemos todos los caracteres con sus coordenadas exactas
                    chars = pagina.chars

                    # Agrupamos caracteres por l√≠nea bas√°ndonos en la coordenada Y
                    lineas_chars = {}
                    for char in chars:
                        # Redondeamos la coordenada Y para agrupar caracteres en la misma l√≠nea
                        y_key = round(char['top'])
                        if y_key not in lineas_chars:
                            lineas_chars[y_key] = []
                        lineas_chars[y_key].append(char)

                    # Ordenamos las l√≠neas por coordenada Y (de arriba hacia abajo)
                    y_keys_ordenadas = sorted(lineas_chars.keys())

                    # Procesamos cada l√≠nea
                    for y_key in y_keys_ordenadas:
                        chars_linea = lineas_chars[y_key]
                        # Ordenamos los caracteres dentro de cada l√≠nea por coordenada X
                        chars_ordenados = sorted(chars_linea, key=lambda c: c['x0'])

                        # Construimos el texto de la l√≠nea
                        texto_linea = ''.join(c['text'] for c in chars_ordenados)

                        # Solo procesamos l√≠neas no vac√≠as
                        if texto_linea.strip():
                            # Guardamos cada car√°cter con sus coordenadas
                            caracteres_por_linea[texto_linea] = chars_ordenados

                            # Agregamos la l√≠nea a la lista ordenada
                            lineas_ordenadas.append(texto_linea)

                            # Detectamos si estamos en la secci√≥n √ÅRBOL
                            if "√ÅRBOL" in texto_linea or "ARBOL" in texto_linea:
                                arbol_iniciado = True
                                print(f"  Encontrada secci√≥n √ÅRBOL: {texto_linea[:50]}...")
                            elif "GRAFO" in texto_linea and arbol_iniciado:
                                arbol_iniciado = False
                                print(f"  Encontrada secci√≥n GRAFO: {texto_linea[:50]}...")
                            elif arbol_iniciado:
                                # Calculamos la posici√≥n X del primer car√°cter no espacio
                                pos_x = None
                                primer_char_no_espacio = None
                                for char in chars_ordenados:
                                    if char['text'].strip():  # Si no es un espacio
                                        pos_x = char['x0']
                                        primer_char_no_espacio = char
                                        break

                                if pos_x is not None:
                                    # Guardamos informaci√≥n detallada para cada l√≠nea del √°rbol
                                    arbol_lineas.append({
                                        'texto': texto_linea,
                                        'posicion_x': pos_x,
                                        'indice': len(lineas_ordenadas) - 1,
                                        'chars': chars_ordenados,
                                        'primer_char': primer_char_no_espacio,
                                        'cuit': extraer_cuit(texto_linea)  # Extraer CUIT
                                    })

                            # Tambi√©n agregamos a la lista global de coordenadas
                            for char in chars_ordenados:
                                todas_coordenadas.append({
                                    'texto': char['text'],
                                    'x0': char['x0'],
                                    'y0': char['top'],
                                    'x1': char['x1'],
                                    'y1': char['bottom'],
                                    'page': page_num,
                                    'linea': texto_linea
                                })

        # Ordenamos las coordenadas globales por p√°gina y posici√≥n Y
        todas_coordenadas = sorted(todas_coordenadas, key=lambda c: (c['page'], c['y0']))

        # Detectar y corregir valores at√≠picos en posiciones X
        # Usamos an√°lisis estad√≠stico para identificar y corregir posiciones an√≥malas
        if len(arbol_lineas) > 5:  # Solo si hay suficientes l√≠neas para analizar
            # Extraer todas las posiciones X
            todas_pos_x = [l['posicion_x'] for l in arbol_lineas]

            # Calcular estad√≠sticas b√°sicas
            media_x = sum(todas_pos_x) / len(todas_pos_x)
            desviacion_x = (sum((x - media_x) ** 2 for x in todas_pos_x) / len(todas_pos_x)) ** 0.5

            # Identificar valores at√≠picos usando el m√©todo de desviaci√≥n est√°ndar
            for linea in arbol_lineas:
                pos_x = linea['posicion_x']
                # Si la posici√≥n est√° muy lejos de la media (m√°s de 2 desviaciones est√°ndar)
                if abs(pos_x - media_x) > 2 * desviacion_x:
                    # Buscar l√≠neas con CUIT similar para determinar nivel jer√°rquico correcto
                    cuit_prefix = linea.get('cuit', '').split('-')[0] if linea.get('cuit', '') else ''
                    lineas_similares = [l for l in arbol_lineas
                                       if l.get('cuit', '').startswith(cuit_prefix)
                                       and abs(l['posicion_x'] - pos_x) <= desviacion_x]

                    if lineas_similares:
                        # Usar la mediana de posiciones X de l√≠neas similares
                        pos_similares = sorted([l['posicion_x'] for l in lineas_similares])
                        mediana_x = pos_similares[len(pos_similares) // 2]
                        linea['posicion_x_corregida'] = mediana_x

        # Normalizar posiciones X detectando y agrupando niveles similares
        if arbol_lineas:
            posiciones_x = [l['posicion_x'] for l in arbol_lineas]

            # Detectar grupos de posiciones X similares (niveles jer√°rquicos)
            grupos_x = agrupar_posiciones_x(posiciones_x)

            # Normalizar las posiciones X basadas en los grupos detectados
            for linea in arbol_lineas:
                for grupo_idx, (min_x, max_x) in enumerate(grupos_x):
                    if min_x <= linea['posicion_x'] <= max_x:
                        # Asignar el valor promedio del grupo como posici√≥n normalizada
                        linea['posicion_x_normalizada'] = (min_x + max_x) / 2
                        linea['nivel_jerarquico'] = grupo_idx
                        break

        # Imprimimos diagn√≥stico de las l√≠neas del √°rbol
        print("\nüìä Diagn√≥stico de l√≠neas del √°rbol:")
        for i, linea in enumerate(arbol_lineas[:min(15, len(arbol_lineas))]):  # Primeras 15 l√≠neas del √°rbol
            pos_x = linea.get('posicion_x_normalizada', linea['posicion_x'])
            print(f"  {i+1}. X={pos_x:.2f} - {linea['texto'][:50]}...")

        # Analizamos si la indentaci√≥n es consistente con la estructura jer√°rquica
        if len(arbol_lineas) > 0:
            # Calculamos la distribuci√≥n de posiciones X
            posiciones_x = [l.get('posicion_x_normalizada', l['posicion_x']) for l in arbol_lineas]
            posiciones_unicas = sorted(set(posiciones_x))

            print("\nüìè Posiciones X √∫nicas encontradas (indentaciones):")
            for i, pos in enumerate(posiciones_unicas[:10]):  # Mostramos hasta 10 posiciones
                print(f"  Indentaci√≥n {i+1}: X={pos:.2f} - {posiciones_x.count(pos)} l√≠neas")

        return '\n'.join(texto_completo), caracteres_por_linea, todas_coordenadas, lineas_ordenadas, arbol_lineas
    except Exception as e:
        print(f"‚ùå Error al extraer texto del PDF {os.path.basename(ruta_pdf)}: {e}")
        import traceback
        traceback.print_exc()
        return "", {}, [], [], []

# Funci√≥n para extraer CUIT de una l√≠nea
def extraer_cuit(linea: str) -> str:
    """Extrae el CUIT de una l√≠nea si existe."""
    patron_cuit = re.compile(r'(\d{2}-\d{8,}-\d)')
    m_cuit = patron_cuit.search(linea)
    if m_cuit:
        return m_cuit.group(1)
    return ""

# Funci√≥n para agrupar posiciones X similares
def agrupar_posiciones_x(posiciones_x: list, umbral: float = 5.0) -> list:
    """
    Agrupa posiciones X similares para identificar niveles jer√°rquicos utilizando
    un algoritmo adaptativo que no requiere conocimiento previo del n√∫mero de niveles.
    Retorna una lista de tuplas (min_x, max_x) para cada grupo.
    """
    if not posiciones_x or len(posiciones_x) < 3:
        # Si hay muy pocos puntos, agrupaci√≥n simple
        if posiciones_x:
            return [(min(posiciones_x), max(posiciones_x))]
        return []

    # Implementaci√≥n de clusterizaci√≥n jer√°rquica adaptativa
    # Primero ordenamos las posiciones
    pos_ordenadas = sorted(posiciones_x)

    # Calculamos las diferencias entre puntos consecutivos
    diferencias = [pos_ordenadas[i+1] - pos_ordenadas[i]
                  for i in range(len(pos_ordenadas)-1)]

    # La mediana de las diferencias nos da una idea del espaciado t√≠pico entre puntos
    # del mismo grupo
    if diferencias:
        diferencias_ordenadas = sorted(diferencias)
        mediana_diferencia = diferencias_ordenadas[len(diferencias_ordenadas) // 2]

        # Usamos un m√∫ltiplo de la mediana como umbral para separar grupos
        # Este enfoque se adapta autom√°ticamente a los datos
        umbral_adaptativo = max(umbral, 2.5 * mediana_diferencia)
    else:
        umbral_adaptativo = umbral

    # Ahora formamos los grupos usando el umbral adaptativo
    grupos = []
    grupo_actual = [pos_ordenadas[0]]

    for pos in pos_ordenadas[1:]:
        # Si la posici√≥n est√° cerca del √∫ltimo valor del grupo actual, agregarla
        if pos - grupo_actual[-1] <= umbral_adaptativo:
            grupo_actual.append(pos)
        else:
            # Si no, cerrar el grupo actual y comenzar uno nuevo
            grupos.append((min(grupo_actual), max(grupo_actual)))
            grupo_actual = [pos]

    # No olvidar el √∫ltimo grupo
    if grupo_actual:
        grupos.append((min(grupo_actual), max(grupo_actual)))

    return grupos

def extraer_seccion(texto_completo: str, patrones: List[str]) -> Optional[str]:
    """Extrae una secci√≥n espec√≠fica del texto seg√∫n patrones."""
    for patron in patrones:
        coincidencia = re.search(patron, texto_completo, re.DOTALL)
        if coincidencia:
            prefijo = "√ÅRBOL" if "√ÅRBOL" in patron else "ARBOL"
            return prefijo + coincidencia.group(1)
    return None

def limpiar_texto(texto: str) -> str:
    """Limpia y normaliza el texto extra√≠do."""
    if not texto:
        return ""

    print(f"Limpiando texto, longitud inicial: {len(texto)}")

    # Patrones para la limpieza
    patron_id = re.compile(r'^(\d{2}-\d{8,}-\d)')
    patron_espacios = re.compile(r'\s{2,}')
    roles = CONFIG['roles']
    tipos_empresa = CONFIG['tipos_empresa']
    prefijos_validos = CONFIG['prefijos_validos']

    lineas_limpias = []
    lineas_originales = texto.split('\n')
    print(f"Total de l√≠neas a procesar: {len(lineas_originales)}")

    for i, linea in enumerate(lineas_originales):
        # Saltar l√≠neas vac√≠as o de sistema
        linea = linea.strip()
        if not linea or linea.startswith("NOSIS.Manager") or "P√°gina" in linea:
            continue

        # Imprimir diagn√≥stico para algunas l√≠neas
        if i < 5 or i % 10 == 0:
            print(f"  Limpiando l√≠nea {i}: {linea[:50]}..." if len(linea) > 50 else f"  Limpiando l√≠nea {i}: {linea}")

        # Normalizar espacios m√∫ltiples primero
        linea = patron_espacios.sub(' ', linea)

        # Buscar l√≠neas que comienzan con CUIT
        if patron_id.match(linea):
            # Ya tiene formato CUIT al inicio, la conservamos como est√°
            lineas_limpias.append(linea)
            continue

        # Si no comienza con CUIT pero contiene uno, intentamos reformatearla
        cuit_en_texto = re.search(r'(\d{2}-\d{8,}-\d)', linea)
        if cuit_en_texto:
            # Reorganizar para que el CUIT est√© al inicio
            cuit = cuit_en_texto.group(1)
            resto = linea.replace(cuit, "").strip()
            linea_reformateada = f"{cuit} {resto}"
            lineas_limpias.append(linea_reformateada)
            if i < 5:
                print(f"    L√≠nea reformateada: {linea_reformateada[:50]}...")
            continue

        # Si llegamos aqu√≠, no pudimos identificar un CUIT
        if i < 5:
            print(f"    ‚ö†Ô∏è No se identific√≥ CUIT, conservando l√≠nea original")
        lineas_limpias.append(linea)

    texto_limpio = '\n'.join(lineas_limpias)
    print(f"Limpieza completada, longitud final: {len(texto_limpio)}")
    return texto_limpio

def extraer_y_limpiar_seccion(ruta_pdf: str) -> Tuple[str, str, dict, list, list, list]:
    """
    Combina la extracci√≥n y limpieza en una sola funci√≥n.
    Retorna una tupla con el texto limpio, un mensaje de estado, un diccionario de caracteres,
    una lista de coordenadas, una lista de l√≠neas ordenadas y una lista de l√≠neas del √°rbol.
    """
    # Extraer todo el texto del PDF junto con las coordenadas
    texto_completo, caracteres_por_linea, todas_coordenadas, lineas_ordenadas, arbol_lineas = extraer_texto_pdf(ruta_pdf)
    if not texto_completo:
        return "", "No se pudo extraer texto del PDF.", {}, [], [], []

    # Extraer la secci√≥n espec√≠fica
    seccion = extraer_seccion(texto_completo, CONFIG['patrones']['arbol_grafo'])
    if not seccion:
        return "", "No se encontraron las secciones ARBOL y GRAFO en el documento.", {}, [], [], []

    # Limpiar el texto de la secci√≥n
    texto_limpio = limpiar_texto(seccion)

    return texto_limpio, "Extracci√≥n exitosa", caracteres_por_linea, todas_coordenadas, lineas_ordenadas, arbol_lineas

def analizar_linea(linea: str, caracteres_por_linea: dict, todas_coordenadas: list, arbol_lineas: list) -> Optional[Dict]:
    """
    Analiza una l√≠nea de texto y extrae sus componentes estructurados.
    Retorna un diccionario con los datos o None si no se pudo analizar.
    """
    # Diagn√≥stico detallado para cada l√≠nea
    print(f"Analizando l√≠nea: {linea[:50]}..." if len(linea) > 50 else f"Analizando l√≠nea: {linea}")

    linea_original = linea  # Guardamos la l√≠nea original para buscar posiciones
    linea = linea.strip()
    if not linea:
        print("  L√≠nea vac√≠a, saltando")
        return None

    # Compilar patrones
    patron_cuit = re.compile(r'^(\d{2}-\d{8,}-\d)')
    patron_edad = re.compile(r'(\d{1,3}\s+a√±os|fallecido)', re.IGNORECASE)
    patron_fecha = re.compile(r'(\d{2}/\d{2}/\d{4})')

    # Extraer CUIT
    m_cuit = patron_cuit.match(linea)
    if not m_cuit:
        print("  No se encontr√≥ patr√≥n CUIT en la l√≠nea")
        return None

    cuit = m_cuit.group(1)
    print(f"  CUIT encontrado: {cuit}")
    resto = linea[len(cuit):].strip()

    # Buscar el primer d√≠gito en el CUIT para la jerarqu√≠a
    jerarquia = ""
    for char in cuit:
        if char.isdigit():
            jerarquia = char
            break

    # Determinar posici√≥n X desde las l√≠neas analizadas
    posicion_x = None
    for linea_arbol in arbol_lineas:
        if cuit in linea_arbol['texto']:
            # Prioridad: posici√≥n corregida, normalizada, o posici√≥n original
            if 'posicion_x_corregida' in linea_arbol:
                posicion_x = linea_arbol['posicion_x_corregida']
            elif 'posicion_x_normalizada' in linea_arbol:
                posicion_x = linea_arbol['posicion_x_normalizada']
            else:
                posicion_x = linea_arbol['posicion_x']
            print(f"  Posici√≥n X encontrada: {posicion_x}")
            break

    if posicion_x is None:
        posicion_x = -1
        print("  No se encontr√≥ posici√≥n X, usando valor por defecto -1")

    # Inicializar datos
    datos = {
        'CUIT': cuit,
        'Nombre': "",
        'Rol': "",
        'Edad': "",
        'Fecha': "",
        'Consultado': "No",
        'Jerarquia': jerarquia,
        'PosicionX': posicion_x
    }

    # Nueva estrategia: Usar expresiones regulares m√°s flexibles para extraer partes
    # Este enfoque ser√° m√°s tolerante a variaciones en el formato

    # 1. Intentar encontrar roles
    roles_pattern = '|'.join(CONFIG['roles'])
    patron_rol = re.compile(f"({roles_pattern})", re.IGNORECASE)
    m_rol = patron_rol.search(resto)

    if m_rol:
        rol = m_rol.group(1)
        pos_rol = m_rol.start()
        print(f"  Rol encontrado: {rol} en posici√≥n {pos_rol}")

        # Extraer nombre (todo lo que est√° antes del rol)
        nombre = resto[:pos_rol].strip()
        datos['Nombre'] = nombre
        datos['Rol'] = rol

        # Resto despu√©s del rol
        resto_despues = resto[pos_rol + len(rol):].strip()

        # Extraer edad
        m_edad = patron_edad.search(resto_despues)
        if m_edad:
            datos['Edad'] = m_edad.group(1).strip()
            if datos['Edad'].lower() == "fallecido":
                datos['Edad'] = "Fallecido"
            print(f"  Edad encontrada: {datos['Edad']}")

        # Extraer fecha
        m_fecha = patron_fecha.search(resto_despues)
        if m_fecha:
            datos['Fecha'] = m_fecha.group(1)
            print(f"  Fecha encontrada: {datos['Fecha']}")

        # Verificar si est√° consultado
        datos['Consultado'] = "S√≠" if "Consultado" in resto_despues else "No"

        print(f"  Registro procesado exitosamente: {datos}")
        return datos
    else:
        print("  No se encontr√≥ un rol v√°lido en la l√≠nea")

    # Si llegamos aqu√≠, no se pudo analizar la l√≠nea correctamente
    return None

def convertir_a_dataframe(texto_limpio: str, caracteres_por_linea: dict, todas_coordenadas: list, arbol_lineas: list) -> Tuple[pd.DataFrame, int]:
    """
    Convierte el texto limpio en un DataFrame estructurado.
    Retorna el DataFrame y el n√∫mero de l√≠neas problem√°ticas.
    """
    print(f"Convirtiendo texto a DataFrame, longitud texto: {len(texto_limpio)}")
    if not texto_limpio:
        print("‚ö†Ô∏è Texto limpio vac√≠o, no se puede crear DataFrame")
        return pd.DataFrame(columns=CONFIG['columnas_df'][:-1]), 0  # Excluimos 'Archivo'

    datos = []
    lineas_problema = 0
    lineas_procesadas = 0

    for i, linea in enumerate(texto_limpio.split('\n')):
        if not linea.strip():
            continue

        lineas_procesadas += 1
        print(f"\nProcesando l√≠nea {lineas_procesadas}: {linea[:50]}..." if len(linea) > 50 else f"\nProcesando l√≠nea {lineas_procesadas}: {linea}")

        # Si encontramos NOSIS.Manager o l√≠neas de sistema, las ignoramos
        if "NOSIS.Manager" in linea or "P√°gina" in linea:
            print("  Ignorando l√≠nea de sistema")
            continue

        registro = analizar_linea(linea, caracteres_por_linea, todas_coordenadas, arbol_lineas)
        if registro:
            datos.append(list(registro.values()))
            print(f"  ‚úÖ L√≠nea convertida a registro: {registro}")
        else:
            lineas_problema += 1
            print(f"  ‚ùå No se pudo analizar la l√≠nea")

    print(f"\nResumen de conversi√≥n: {len(datos)} registros creados, {lineas_problema} l√≠neas problem√°ticas")
    if datos:
        df = pd.DataFrame(datos, columns=CONFIG['columnas_df'][:-1])  # Excluimos 'Archivo'
        print(f"DataFrame creado con {len(df)} filas y {len(df.columns)} columnas")
        return df, lineas_problema
    else:
        print("‚ö†Ô∏è No se crearon registros, DataFrame vac√≠o")
        return pd.DataFrame(columns=CONFIG['columnas_df'][:-1]), lineas_problema

def mostrar_estadisticas(df: pd.DataFrame) -> None:
    """Muestra estad√≠sticas b√°sicas del DataFrame."""
    if df.empty:
        print("‚ùå No se extrajeron datos estructurados.")
        return

    print(f"üìä Total registros: {len(df)}")
    print(f"üîé Roles √∫nicos: {df['Rol'].nunique()}")
    print(f"Distribuci√≥n de roles:")
    print(df['Rol'].value_counts().head())
    print(f"üìä Distribuci√≥n de jerarqu√≠as:")
    print(df['Jerarquia'].value_counts())
    print(f"üìè Rango de posiciones X: {df['PosicionX'].min()} - {df['PosicionX'].max()}")
    print("\nüß™ Primeros registros:")
    print(df.head().to_string())

def procesar_archivo(ruta_pdf: str) -> pd.DataFrame:
    """
    Procesa un √∫nico archivo PDF y retorna su DataFrame.
    """
    print(f"\nüìÇ Procesando archivo: {ruta_pdf}")

    try:
        # Extraer y limpiar texto
        texto_extraido, mensaje, caracteres_por_linea, todas_coordenadas, lineas_ordenadas, arbol_lineas = extraer_y_limpiar_seccion(ruta_pdf)
        if not texto_extraido:
            print(f"‚ö†Ô∏è {mensaje}")
            return pd.DataFrame(columns=CONFIG['columnas_df'])

        print(f"üìù Texto extra√≠do correctamente")

        # Vamos a mostrar las primeras l√≠neas del texto extra√≠do para diagn√≥stico
        print("\nMuestra del texto extra√≠do:")
        lineas_muestra = texto_extraido.split('\n')[:10]  # Primeras 10 l√≠neas
        for i, linea in enumerate(lineas_muestra):
            print(f"  {i+1}. {linea[:70]}..." if len(linea) > 70 else f"  {i+1}. {linea}")

        # Informaci√≥n sobre las l√≠neas del √°rbol encontradas
        print(f"\nüìã Se encontraron {len(arbol_lineas)} l√≠neas en la secci√≥n √ÅRBOL")

        # Mostrar algunas l√≠neas del √°rbol para diagn√≥stico
        print("\nüìä Muestra de l√≠neas del √°rbol con sus posiciones X:")
        for i, linea_info in enumerate(arbol_lineas[:10]):  # Primeras 10 l√≠neas
            print(f"  {i+1}. X={linea_info['posicion_x']:.2f} - {linea_info['texto'][:50]}...")

        # Convertir a DataFrame
        df, lineas_problema = convertir_a_dataframe(texto_extraido, caracteres_por_linea, todas_coordenadas, arbol_lineas)
        if lineas_problema > 0:
            print(f"‚ö†Ô∏è No se pudieron analizar {lineas_problema} l√≠neas.")

        if df.empty:
            print("‚ö†Ô∏è No se extrajeron datos estructurados.")
            return pd.DataFrame(columns=CONFIG['columnas_df'])

        # Agregar columna con el nombre del archivo
        df['Archivo'] = os.path.basename(ruta_pdf)

        # Mostrar estad√≠sticas
        mostrar_estadisticas(df)

        return df
    except Exception as e:
        print(f"‚ùå Error procesando {ruta_pdf}: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame(columns=CONFIG['columnas_df'])

def procesar_archivos_batch(archivos: List[str], max_workers: int = 1) -> pd.DataFrame:
    """
    Procesa m√∫ltiples archivos en paralelo y combina sus resultados.
    Reducido a 1 worker para mejor diagn√≥stico.
    """
    if not archivos:
        print("No se proporcionaron archivos para procesar.")
        return pd.DataFrame(columns=CONFIG['columnas_df'])

    todos_dfs = []

    # Procesamiento secuencial para mejor diagn√≥stico
    if max_workers == 1:
        for archivo in tqdm(archivos, desc="Procesando archivos"):
            df = procesar_archivo(archivo)
            if not df.empty:
                todos_dfs.append(df)
    else:
        # Procesamiento paralelo para m√∫ltiples archivos
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            resultados = list(tqdm(
                executor.map(procesar_archivo, archivos),
                total=len(archivos),
                desc="Procesando archivos"
            ))

        for df in resultados:
            if not df.empty:
                todos_dfs.append(df)

    # Combinar resultados
    if todos_dfs:
        resultado_final = pd.concat(todos_dfs, ignore_index=True)
        print(f"\nüìö Archivos combinados: {len(todos_dfs)} con un total de {len(resultado_final)} registros.")
        return resultado_final
    else:
        print("\n‚ö†Ô∏è No se obtuvieron datos de ning√∫n archivo.")
        return pd.DataFrame(columns=CONFIG['columnas_df'])

def cargar_desde_drive(ruta_drive: str = "Desarrollo/insumo_prueba") -> List[str]:
    """
    Carga archivos PDF desde una carpeta espec√≠fica de Google Drive.

    Args:
        ruta_drive: Ruta relativa a la ra√≠z de Google Drive

    Returns:
        Lista de rutas a archivos PDF encontrados
    """
    # Verificar si estamos en Colab
    if not IN_COLAB:
        print("Esta funci√≥n solo est√° disponible en Google Colab.")
        return []

    try:
        # Montar Google Drive
        drive.mount('/content/drive')

        # Construir la ruta completa - Nota: "Mi unidad" se mapea a "/content/drive/MyDrive" en Colab
        ruta_completa = f"/content/drive/MyDrive/{ruta_drive}"

        # Verificar que la carpeta existe
        if not os.path.exists(ruta_completa):
            print(f"‚ö†Ô∏è La carpeta {ruta_completa} no existe.")
            # Intentemos listar las carpetas en el directorio ra√≠z para ayudar al usuario
            print("\nCarpetas disponibles en la ra√≠z de Google Drive:")
            root_dir = "/content/drive/MyDrive"
            if os.path.exists(root_dir):
                print([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])
            return []

        print(f"üìÇ Buscando archivos PDF en: {ruta_completa}")

        # Listar archivos PDF en la carpeta
        pdf_files = [
            os.path.join(ruta_completa, f) for f in os.listdir(ruta_completa)
            if f.lower().endswith('.pdf')
        ]

        if not pdf_files:
            print("‚ö†Ô∏è No se encontraron archivos PDF en la carpeta especificada.")
        else:
            print(f"‚úÖ Se encontraron {len(pdf_files)} archivos PDF.")
            for pdf in pdf_files:
                print(f"  - {os.path.basename(pdf)}")

        return pdf_files

    except Exception as e:
        print(f"‚ùå Error al acceder a Google Drive: {e}")
        # Mostrar un mensaje m√°s √∫til
        print("\nVerifica que:")
        print("1. Tu Google Drive est√° correctamente montado")
        print("2. La ruta es correcta (normalmente comienza desde 'MyDrive' no desde 'Mi unidad')")
        print("3. Tienes permisos para acceder a esa carpeta")
        return []

def main() -> pd.DataFrame:
    """
    Funci√≥n principal que coordina el proceso de extracci√≥n.
    Solicita archivos al usuario y los procesa.
    """
    print("üîç Iniciando extractor de PDF a DataFrame")

    # Opciones para cargar archivos
    if IN_COLAB:
        print("\nSelecciona c√≥mo quieres cargar los archivos:")
        print("1. Buscar PDFs en el directorio actual")
        print("2. Usar archivos desde Google Drive (Desarrollo/insumo_prueba)")
        print("3. Especificar otra carpeta en Google Drive")
        print("4. Subir archivos PDF manualmente")

        opcion = input("\nIngresa el n√∫mero de la opci√≥n (1-4): ").strip()

        if opcion == "1":
            # Buscar en el directorio actual
            current_dir = os.getcwd()
            pdfs_encontrados = [f for f in os.listdir(current_dir) if f.lower().endswith('.pdf')]
            if pdfs_encontrados:
                print(f"Se encontraron {len(pdfs_encontrados)} PDFs en el directorio actual.")
                rutas_archivos = [os.path.join(current_dir, pdf) for pdf in pdfs_encontrados]
            else:
                print("No se encontraron PDFs en el directorio actual.")
                return pd.DataFrame(columns=CONFIG['columnas_df'])
        elif opcion == "2":
            # Usar la ruta predeterminada
            rutas_archivos = cargar_desde_drive()
        elif opcion == "3":
            # Pedir una ruta personalizada
            print("\nNota: En Colab, 'Mi unidad' se accede como 'MyDrive'")
            ruta_personalizada = input("\nIngresa la ruta dentro de Google Drive (ej: Carpeta/Subcarpeta): ")
            rutas_archivos = cargar_desde_drive(ruta_personalizada)
        elif opcion == "4":
            # Subir archivos manualmente
            print("\nPor favor, sube tus archivos PDF:")
            uploaded = files.upload()
            rutas_archivos = list(uploaded.keys())
        else:
            print("‚ö†Ô∏è Opci√≥n no v√°lida. Buscando PDFs en el directorio actual.")
            current_dir = os.getcwd()
            pdfs_encontrados = [f for f in os.listdir(current_dir) if f.lower().endswith('.pdf')]
            if pdfs_encontrados:
                rutas_archivos = [os.path.join(current_dir, pdf) for pdf in pdfs_encontrados]
            else:
                print("No se encontraron PDFs en el directorio actual.")
                return pd.DataFrame(columns=CONFIG['columnas_df'])
    else:
        # Si no estamos en Colab, buscar PDFs en el directorio actual
        current_dir = os.getcwd()
        pdfs_encontrados = [f for f in os.listdir(current_dir) if f.lower().endswith('.pdf')]

        if pdfs_encontrados:
            print(f"Se encontraron {len(pdfs_encontrados)} PDFs en el directorio actual.")
            rutas_archivos = [os.path.join(current_dir, pdf) for pdf in pdfs_encontrados]
        else:
            # Pedir ruta de archivo manualmente
            ruta = input("No se encontraron PDFs. Ingresa la ruta al directorio o archivo PDF: ")
            if os.path.isdir(ruta):
                rutas_archivos = [
                    os.path.join(ruta, f) for f in os.listdir(ruta)
                    if f.lower().endswith('.pdf')
                ]
            else:
                rutas_archivos = [ruta]

    if not rutas_archivos:
        print("No se encontraron archivos PDF para procesar.")
        return pd.DataFrame(columns=CONFIG['columnas_df'])

    # Procesar archivos (usando 1 worker para mejor diagn√≥stico)
    df_final = procesar_archivos_batch(rutas_archivos, max_workers=1)

    # Mostrar el DataFrame final
    print("\nüìä DataFrame Final:")
    if df_final.empty:
        print("No se extrajeron datos de ning√∫n archivo.")
    else:
        # Mostrar estad√≠sticas generales
        print(f"Total de registros: {len(df_final)}")
        print(f"Columnas: {', '.join(df_final.columns)}")
        print(f"Archivos procesados: {df_final['Archivo'].nunique()}")
        print(f"Roles encontrados: {df_final['Rol'].nunique()}")
        print(f"Jerarqu√≠as encontradas: {df_final['Jerarquia'].nunique()}")
        print(f"Rango de posiciones X: {df_final['PosicionX'].min()} - {df_final['PosicionX'].max()}")

        # Mostrar una muestra del DataFrame
        print("\nMuestra del DataFrame:")
        pd.set_option('display.max_columns', None)  # Mostrar todas las columnas
        print(df_final.head(10).to_string())

        # Buscar espec√≠ficamente la fila con el CUIT problem√°tico
        if '23-05061924-9' in df_final['CUIT'].values:
            print("\nFila con CUIT 23-05061924-9 (MEDICA JORGE LUIS):")
            print(df_final[df_final['CUIT'] == '23-05061924-9'].to_string())

        # Guardar en CSV
        try:
            csv_path = 'resultados_estructurados.csv'
            df_final.to_csv(csv_path, index=False)
            print(f"\n‚úÖ Resultados guardados en: {csv_path}")
        except Exception as e:
            print(f"\n‚ùå Error al guardar CSV: {e}")

    return df_final

# Ejecutar el script si se ejecuta directamente
if __name__ == "__main__":
    try:
        df_final = main()

        # Configurar pandas para mostrar todos los datos
        pd.set_option('display.max_columns', None)
        pd.set_option('display.max_rows', 100)
        pd.set_option('display.width', 1000)

        # Mostrar resultados finales
        print("\n\nüìä RESULTADOS FINALES DEL PROCESAMIENTO:")
        if df_final.empty:
            print("‚ö†Ô∏è No se obtuvieron resultados.")
        else:
            # Verificar posici√≥n X para el CUIT problem√°tico
            if '23-05061924-9' in df_final['CUIT'].values:
                fila_problema = df_final[df_final['CUIT'] == '23-05061924-9']
                print(f"\n‚úÖ Se proces√≥ correctamente el CUIT problem√°tico 23-05061924-9:")
                print(f"   Posici√≥n X: {fila_problema['PosicionX'].values[0]}")
                print(f"   Nombre: {fila_problema['Nombre'].values[0]}")
                print(f"   Rol: {fila_problema['Rol'].values[0]}")

            # Mostrar estad√≠sticas de posiciones X por nivel jer√°rquico
            print("\nüìä Estad√≠sticas por jerarqu√≠a:")
            for jerarquia in sorted(df_final['Jerarquia'].unique()):
                if not pd.isna(jerarquia) and jerarquia:  # Ignorar valores vac√≠os o NaN
                    grupo = df_final[df_final['Jerarquia'] == jerarquia]
                    if not grupo.empty:
                        print(f"\nJerarqu√≠a {jerarquia}:")
                        print(f"  - Registros: {len(grupo)}")
                        print(f"  - Posici√≥nX media: {grupo['PosicionX'].mean():.2f}")
                        print(f"  - Posici√≥nX min-max: {grupo['PosicionX'].min():.2f} - {grupo['PosicionX'].max():.2f}")

    except Exception as e:
        print(f"\n‚ùå Error en la ejecuci√≥n principal: {e}")
        import traceback
        traceback.print_exc()

df_final